{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-small model finetuning (with cyclical learning rate schedule)\n",
    "=======================================================\n",
    "\n",
    "In this notebook we:\n",
    "- Use a small model (no dense or residual connections), 6 level pyramid, uspample level 2 by 4 as the final flow prediction\n",
    "- Train the PWC-Net-small model on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` dataset using a Cyclic<sub>short</sub> schedule of our own\n",
    "- Let the Cyclic<sub>short</sub> schedule oscillate between `2e-05` and `1e-06` for 200,000 steps\n",
    "- Switch to the \"robust\" loss described in the paper, instead of the \"multiscale\" loss used during training\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_finetune.ipynb\n",
    "\n",
    "PWC-Net model finetuning.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset_base import _DEFAULT_DS_TUNE_OPTIONS\n",
    "from dataset_flyingchairs import FlyingChairsDataset\n",
    "from dataset_flyingthings3d import FlyingThings3DHalfResDataset\n",
    "from dataset_mixer import MixedDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_FINETUNE_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/media/EDrive/datasets/'\n",
    "_FLYINGCHAIRS_ROOT = _DATASET_ROOT + 'FlyingChairs_release'\n",
    "_FLYINGTHINGS3DHALFRES_ROOT = _DATASET_ROOT + 'FlyingThings3D_HalfRes'\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "# gpu_devices = ['/device:GPU:0', '/device:GPU:1']\n",
    "# controller = '/device:CPU:0'\n",
    "gpu_devices = ['/device:GPU:0']\n",
    "controller = '/device:GPU:0'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune on `FlyingChairs+FlyingThings3DHalfRes` mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TUNE_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Use a multiple of 8; here, 16 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (256, 448)                  # Crop to a smaller input size\n",
    "ds1 = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)\n",
    "ds_opts['type'] = 'into_future'\n",
    "ds2 = FlyingThings3DHalfResDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3DHALFRES_ROOT, options=ds_opts)\n",
    "ds = MixedDataset(mode='train_with_val', datasets=[ds1, ds2], options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (256, 448)\n",
      "  scale_preproc        None\n",
      "  input_channels       3\n",
      "  type                 into_future\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             heavy\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           8\n",
      "  mode                 train_with_val\n",
      "  train size           41282\n",
      "  val size             1230\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_FINETUNE_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = './models/pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-49000'\n",
    "nn_opts['ckpt_dir'] = './pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model in quarter-resolution mode\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# Robust loss as described doesn't work, so try the following:\n",
    "nn_opts['loss_fn'] = 'loss_multiscale' # 'loss_multiscale' # 'loss_robust' # 'loss_robust'\n",
    "nn_opts['q'] = 1. # 0.4 # 1. # 0.4 # 1.\n",
    "nn_opts['epsilon'] = 0. # 0.01 # 0. # 0.01 # 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'multisteps'\n",
    "nn_opts['init_lr'] = 1e-05\n",
    "nn_opts['lr_boundaries'] = [80000, 120000, 160000, 200000]\n",
    "nn_opts['lr_values'] = [1e-05, 5e-06, 2.5e-06, 1.25e-06, 6.25e-07]\n",
    "nn_opts['max_steps'] = 200000\n",
    "\n",
    "# Below,we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] * 8 / ds_opts['batch_size'])\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] * 8 / ds_opts['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "WARNING:tensorflow:From e:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "... model built.\n",
      "Configuring training ops...\n",
      "... training ops configured.\n",
      "Initializing from pre-trained model at ./models/pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-49000 for finetuning...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-49000\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_path              ./models/pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-49000\n",
      "  ckpt_dir               ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/\n",
      "  max_to_keep            10\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 256, 448, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [256, 448, 2]\n",
      "  train_mode             fine-tune\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            top_flow\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:0']\n",
      "  controller             /device:GPU:0\n",
      "  use_tf_data            True\n",
      "  use_mixed_precision    False\n",
      "  loss_scaler            8.0\n",
      "  batch_size             8\n",
      "  lr_policy              multisteps\n",
      "  max_steps              200000\n",
      "  lr_boundaries          [80000, 120000, 160000, 200000]\n",
      "  lr_values              [1e-05, 5e-06, 2.5e-06, 1.25e-06, 6.25e-07]\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           False\n",
      "  use_res_cx             False\n",
      "  mode                   train_with_val\n",
      "  trainable params       4705064\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start finetuning...\n",
      "2018-09-13 21:56:06 Iter 100 [Train]: loss=63.62, epe=4.41, lr=0.000010, samples/sec=15.1, sec/step=0.530, eta=1 day, 5:27:21\n",
      "2018-09-13 21:56:37 Iter 200 [Train]: loss=66.90, epe=4.64, lr=0.000010, samples/sec=28.1, sec/step=0.285, eta=15:49:40\n",
      "2018-09-13 21:57:07 Iter 300 [Train]: loss=66.52, epe=4.63, lr=0.000010, samples/sec=28.2, sec/step=0.283, eta=15:43:09\n",
      "2018-09-13 21:57:39 Iter 400 [Train]: loss=60.83, epe=4.21, lr=0.000010, samples/sec=27.0, sec/step=0.297, eta=16:26:57\n",
      "2018-09-13 21:58:10 Iter 500 [Train]: loss=67.52, epe=4.71, lr=0.000010, samples/sec=28.0, sec/step=0.286, eta=15:50:04\n",
      "2018-09-13 21:58:40 Iter 600 [Train]: loss=58.98, epe=4.08, lr=0.000010, samples/sec=28.3, sec/step=0.283, eta=15:39:55\n",
      "2018-09-13 21:59:12 Iter 700 [Train]: loss=69.42, epe=4.82, lr=0.000010, samples/sec=27.2, sec/step=0.294, eta=16:17:36\n",
      "2018-09-13 21:59:43 Iter 800 [Train]: loss=64.24, epe=4.45, lr=0.000010, samples/sec=27.4, sec/step=0.292, eta=16:08:58\n",
      "2018-09-13 22:00:14 Iter 900 [Train]: loss=68.52, epe=4.83, lr=0.000010, samples/sec=27.0, sec/step=0.297, eta=16:24:34\n",
      "2018-09-13 22:00:48 Iter 1000 [Train]: loss=66.92, epe=4.66, lr=0.000010, samples/sec=25.5, sec/step=0.313, eta=17:18:31\n",
      "2018-09-13 22:01:08 Iter 1000 [Val]: loss=66.70, epe=4.69\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-1000\n",
      "2018-09-13 22:01:48 Iter 1100 [Train]: loss=67.75, epe=4.71, lr=0.000010, samples/sec=26.7, sec/step=0.300, eta=16:34:53\n",
      "2018-09-13 22:02:21 Iter 1200 [Train]: loss=65.25, epe=4.51, lr=0.000010, samples/sec=25.4, sec/step=0.315, eta=17:24:29\n",
      "2018-09-13 22:02:55 Iter 1300 [Train]: loss=60.71, epe=4.16, lr=0.000010, samples/sec=25.2, sec/step=0.317, eta=17:29:23\n",
      "2018-09-13 22:03:31 Iter 1400 [Train]: loss=63.57, epe=4.40, lr=0.000010, samples/sec=23.9, sec/step=0.334, eta=18:27:10\n",
      "2018-09-13 22:04:06 Iter 1500 [Train]: loss=66.19, epe=4.60, lr=0.000010, samples/sec=24.1, sec/step=0.332, eta=18:17:19\n",
      "2018-09-13 22:04:42 Iter 1600 [Train]: loss=60.38, epe=4.14, lr=0.000010, samples/sec=23.0, sec/step=0.348, eta=19:09:12\n",
      "2018-09-13 22:05:19 Iter 1700 [Train]: loss=65.62, epe=4.53, lr=0.000010, samples/sec=23.2, sec/step=0.344, eta=18:57:50\n",
      "2018-09-13 22:05:55 Iter 1800 [Train]: loss=69.20, epe=4.83, lr=0.000010, samples/sec=23.2, sec/step=0.344, eta=18:56:50\n",
      "2018-09-13 22:06:36 Iter 1900 [Train]: loss=62.05, epe=4.27, lr=0.000010, samples/sec=20.8, sec/step=0.384, eta=21:07:19\n",
      "2018-09-13 22:07:14 Iter 2000 [Train]: loss=60.91, epe=4.19, lr=0.000010, samples/sec=21.7, sec/step=0.368, eta=20:14:57\n",
      "2018-09-13 22:07:32 Iter 2000 [Val]: loss=66.49, epe=4.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-2000\n",
      "2018-09-13 22:08:19 Iter 2100 [Train]: loss=62.83, epe=4.33, lr=0.000010, samples/sec=20.6, sec/step=0.389, eta=21:23:13\n",
      "2018-09-13 22:09:01 Iter 2200 [Train]: loss=65.57, epe=4.60, lr=0.000010, samples/sec=20.2, sec/step=0.396, eta=21:44:04\n",
      "2018-09-13 22:09:43 Iter 2300 [Train]: loss=63.27, epe=4.38, lr=0.000010, samples/sec=20.2, sec/step=0.395, eta=21:43:07\n",
      "2018-09-13 22:10:28 Iter 2400 [Train]: loss=63.28, epe=4.38, lr=0.000010, samples/sec=18.6, sec/step=0.431, eta=23:38:16\n",
      "2018-09-13 22:11:13 Iter 2500 [Train]: loss=69.06, epe=4.81, lr=0.000010, samples/sec=18.7, sec/step=0.427, eta=23:25:03\n",
      "2018-09-13 22:12:01 Iter 2600 [Train]: loss=70.28, epe=4.95, lr=0.000010, samples/sec=17.1, sec/step=0.468, eta=1 day, 1:40:24\n",
      "2018-09-13 22:12:52 Iter 2700 [Train]: loss=59.87, epe=4.11, lr=0.000010, samples/sec=16.6, sec/step=0.482, eta=1 day, 2:25:30\n",
      "2018-09-13 22:13:45 Iter 2800 [Train]: loss=69.98, epe=4.87, lr=0.000010, samples/sec=15.6, sec/step=0.513, eta=1 day, 4:06:29\n",
      "2018-09-13 22:14:39 Iter 2900 [Train]: loss=67.23, epe=4.69, lr=0.000010, samples/sec=15.3, sec/step=0.522, eta=1 day, 4:33:50\n",
      "2018-09-13 22:15:38 Iter 3000 [Train]: loss=60.99, epe=4.19, lr=0.000010, samples/sec=13.9, sec/step=0.576, eta=1 day, 7:30:15\n",
      "2018-09-13 22:15:56 Iter 3000 [Val]: loss=65.44, epe=4.58\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-3000\n",
      "2018-09-13 22:16:59 Iter 3100 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.4, sec/step=0.555, eta=1 day, 6:21:45\n",
      "2018-09-13 22:17:56 Iter 3200 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.7, sec/step=0.544, eta=1 day, 5:44:52\n",
      "2018-09-13 22:18:53 Iter 3300 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.5, sec/step=0.551, eta=1 day, 6:05:06\n",
      "2018-09-13 22:19:50 Iter 3400 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.4, sec/step=0.556, eta=1 day, 6:22:27\n",
      "2018-09-13 22:20:46 Iter 3500 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.9, sec/step=0.538, eta=1 day, 5:22:56\n",
      "2018-09-13 22:21:41 Iter 3600 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=15.0, sec/step=0.535, eta=1 day, 5:11:26\n",
      "2018-09-13 22:22:37 Iter 3700 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=15.0, sec/step=0.534, eta=1 day, 5:05:48\n",
      "2018-09-13 22:23:35 Iter 3800 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.2, sec/step=0.563, eta=1 day, 6:42:06\n",
      "2018-09-13 22:24:32 Iter 3900 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.4, sec/step=0.554, eta=1 day, 6:11:44\n",
      "2018-09-13 22:25:29 Iter 4000 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.5, sec/step=0.551, eta=1 day, 5:59:24\n",
      "2018-09-13 22:25:47 Iter 4000 [Val]: loss=nan, epe=nan\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-4000\n",
      "2018-09-13 22:26:49 Iter 4100 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.8, sec/step=0.541, eta=1 day, 5:27:00\n",
      "2018-09-13 22:27:47 Iter 4200 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.0, sec/step=0.570, eta=1 day, 6:59:51\n",
      "2018-09-13 22:28:44 Iter 4300 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.6, sec/step=0.546, eta=1 day, 5:41:33\n",
      "2018-09-13 22:29:41 Iter 4400 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.7, sec/step=0.543, eta=1 day, 5:31:28\n",
      "2018-09-13 22:30:37 Iter 4500 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.6, sec/step=0.549, eta=1 day, 5:47:22\n",
      "2018-09-13 22:31:34 Iter 4600 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.7, sec/step=0.545, eta=1 day, 5:35:48\n",
      "2018-09-13 22:32:31 Iter 4700 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.6, sec/step=0.546, eta=1 day, 5:37:45\n",
      "2018-09-13 22:33:28 Iter 4800 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.5, sec/step=0.553, eta=1 day, 5:58:58\n",
      "2018-09-13 22:34:26 Iter 4900 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.3, sec/step=0.559, eta=1 day, 6:18:38\n",
      "2018-09-13 22:35:21 Iter 5000 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.8, sec/step=0.539, eta=1 day, 5:11:54\n",
      "2018-09-13 22:35:39 Iter 5000 [Val]: loss=nan, epe=nan\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-5000\n",
      "2018-09-13 22:36:41 Iter 5100 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=14.7, sec/step=0.542, eta=1 day, 5:21:52\n",
      "2018-09-13 22:37:24 Iter 5200 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=19.3, sec/step=0.414, eta=22:22:52\n",
      "2018-09-13 22:37:54 Iter 5300 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=28.4, sec/step=0.282, eta=15:14:06\n",
      "2018-09-13 22:38:24 Iter 5400 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=28.3, sec/step=0.283, eta=15:16:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-13 22:38:55 Iter 5500 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=27.7, sec/step=0.288, eta=15:34:46\n",
      "2018-09-13 22:39:26 Iter 5600 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=27.8, sec/step=0.288, eta=15:33:30\n",
      "2018-09-13 22:39:57 Iter 5700 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=27.9, sec/step=0.286, eta=15:27:38\n",
      "2018-09-13 22:40:28 Iter 5800 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=26.8, sec/step=0.298, eta=16:05:40\n",
      "2018-09-13 22:41:00 Iter 5900 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=27.0, sec/step=0.296, eta=15:56:51\n",
      "2018-09-13 22:41:33 Iter 6000 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=25.8, sec/step=0.310, eta=16:42:53\n",
      "2018-09-13 22:41:51 Iter 6000 [Val]: loss=nan, epe=nan\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-6000\n",
      "2018-09-13 22:42:27 Iter 6100 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=27.5, sec/step=0.291, eta=15:41:14\n",
      "2018-09-13 22:43:00 Iter 6200 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=26.1, sec/step=0.306, eta=16:28:23\n",
      "2018-09-13 22:43:34 Iter 6300 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=25.3, sec/step=0.316, eta=16:59:20\n",
      "2018-09-13 22:44:06 Iter 6400 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=25.9, sec/step=0.309, eta=16:36:26\n",
      "2018-09-13 22:44:41 Iter 6500 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=24.2, sec/step=0.330, eta=17:45:07\n",
      "2018-09-13 22:45:16 Iter 6600 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=24.4, sec/step=0.328, eta=17:38:00\n",
      "2018-09-13 22:45:53 Iter 6700 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=22.7, sec/step=0.353, eta=18:56:07\n",
      "2018-09-13 22:46:29 Iter 6800 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=23.5, sec/step=0.340, eta=18:15:17\n",
      "2018-09-13 22:47:05 Iter 6900 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=23.5, sec/step=0.341, eta=18:16:16\n",
      "2018-09-13 22:47:41 Iter 7000 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=23.6, sec/step=0.340, eta=18:12:08\n",
      "2018-09-13 22:47:59 Iter 7000 [Val]: loss=nan, epe=nan\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/pwcnet.ckpt-7000\n",
      "2018-09-13 22:48:43 Iter 7100 [Train]: loss=nan, epe=nan, lr=0.000010, samples/sec=21.9, sec/step=0.365, eta=19:33:58\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b1d44099aeaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\repos\\tf-optflow\\tfoptflow\\model_pwcnet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_tnsr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_adapt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_tnsr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_adapt\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hat_train_tnsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[0mduration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostproc_y_hat_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# y_hat: [107.0802, 5.8556495, None]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/loss.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/epe.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions issued by the model for a few validation samples:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val1.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val2.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val3.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val4.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val5.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val6.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val7.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
